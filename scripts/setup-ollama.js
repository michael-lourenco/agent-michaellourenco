#!/usr/bin/env node

/**
 * Script para configurar o Ollama
 * IA local gratuita como alternativa Ã  OpenAI
 */

const fs = require('fs');
const path = require('path');

console.log('ğŸ¦™ **CONFIGURAÃ‡ÃƒO DO OLLAMA**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
console.log('');

console.log('ğŸ¯ **O QUE Ã‰ O OLLAMA?**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
console.log('â€¢ IA local que roda no seu computador');
console.log('â€¢ Totalmente gratuito (sem custos de API)');
console.log('â€¢ Modelos como Llama 2, Mistral, CodeLlama');
console.log('â€¢ Funciona offline');
console.log('â€¢ Privacidade total (dados ficam no seu PC)');
console.log('');

const envPath = path.join(__dirname, '..', '.env');

// Verificar se o arquivo .env existe
if (!fs.existsSync(envPath)) {
  console.log('âŒ Arquivo .env nÃ£o encontrado!');
  console.log('ğŸ’¡ Execute: cp env.example .env');
  process.exit(1);
}

// Ler o arquivo .env
const envContent = fs.readFileSync(envPath, 'utf8');
const lines = envContent.split('\n');

// Verificar configuraÃ§Ã£o atual
const ollamaUrlLine = lines.find(line => line.startsWith('OLLAMA_BASE_URL='));
const ollamaModelLine = lines.find(line => line.startsWith('OLLAMA_MODEL='));

const currentUrl = ollamaUrlLine ? ollamaUrlLine.split('=')[1] : null;
const currentModel = ollamaModelLine ? ollamaModelLine.split('=')[1] : null;

console.log('ğŸ“Š **CONFIGURAÃ‡ÃƒO ATUAL**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

if (currentUrl && currentUrl !== 'mock_ollama_url') {
  console.log('âœ… Ollama configurado!');
  console.log(`URL: ${currentUrl}`);
  console.log(`Modelo: ${currentModel || 'llama2'}`);
} else {
  console.log('âš ï¸  Ollama nÃ£o configurado');
}

console.log('');
console.log('ğŸš€ **COMO INSTALAR O OLLAMA**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

console.log('1. **Instalar Ollama:**');
console.log('   Acesse: https://ollama.ai/download');
console.log('   Baixe para seu sistema operacional');
console.log('   Instale seguindo as instruÃ§Ãµes');
console.log('');

console.log('2. **Baixar um modelo:**');
console.log('   # Modelo recomendado (equilibrado)');
console.log('   ollama pull llama2');
console.log('');
console.log('   # Modelo mais rÃ¡pido');
console.log('   ollama pull mistral');
console.log('');
console.log('   # Modelo para cÃ³digo');
console.log('   ollama pull codellama');
console.log('');

console.log('3. **Testar instalaÃ§Ã£o:**');
console.log('   ollama run llama2 "OlÃ¡, como vocÃª estÃ¡?"');
console.log('');

console.log('4. **Configurar no projeto:**');
console.log('   Edite o arquivo .env e adicione:');
console.log('   OLLAMA_BASE_URL=http://localhost:11434');
console.log('   OLLAMA_MODEL=llama2');
console.log('');

console.log('ğŸ”§ **CONFIGURAÃ‡ÃƒO AUTOMÃTICA**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

// Verificar se precisa configurar
if (!currentUrl || currentUrl === 'mock_ollama_url') {
  console.log('ğŸ“ Configurando Ollama no .env...');
  
  // Encontrar ou criar linhas do Ollama
  let ollamaUrlIndex = lines.findIndex(line => line.startsWith('OLLAMA_BASE_URL='));
  let ollamaModelIndex = lines.findIndex(line => line.startsWith('OLLAMA_MODEL='));
  
  if (ollamaUrlIndex === -1) {
    // Adicionar linha do OLLAMA_BASE_URL
    lines.push('OLLAMA_BASE_URL=http://localhost:11434');
  } else {
    lines[ollamaUrlIndex] = 'OLLAMA_BASE_URL=http://localhost:11434';
  }
  
  if (ollamaModelIndex === -1) {
    // Adicionar linha do OLLAMA_MODEL
    lines.push('OLLAMA_MODEL=llama2');
  } else {
    lines[ollamaModelIndex] = 'OLLAMA_MODEL=llama2';
  }
  
  // Salvar arquivo
  fs.writeFileSync(envPath, lines.join('\n'));
  
  console.log('âœ… Ollama configurado no .env!');
  console.log('   OLLAMA_BASE_URL=http://localhost:11434');
  console.log('   OLLAMA_MODEL=llama2');
} else {
  console.log('âœ… Ollama jÃ¡ estÃ¡ configurado!');
}

console.log('');
console.log('ğŸ§ª **TESTE RÃPIDO**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

console.log('1. **Iniciar Ollama:**');
console.log('   ollama serve');
console.log('');
console.log('2. **Em outro terminal, testar:**');
console.log('   yarn dev');
console.log('');
console.log('3. **Testar no Telegram:**');
console.log('   Envie uma mensagem para o bot');
console.log('   Verifique os logs da aplicaÃ§Ã£o');
console.log('');

console.log('ğŸ“Š **COMPARAÃ‡ÃƒO DE MODELOS**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

console.log('| Modelo | Tamanho | Velocidade | Qualidade | Uso Recomendado |');
console.log('|--------|---------|------------|-----------|-----------------|');
console.log('| llama2 | 3.8GB | MÃ©dia | Boa | Geral |');
console.log('| mistral | 4.1GB | RÃ¡pida | Muito Boa | Geral |');
console.log('| codellama | 6.7GB | Lenta | Excelente | CÃ³digo |');
console.log('| llama2:7b | 3.8GB | RÃ¡pida | Boa | Desenvolvimento |');
console.log('| llama2:13b | 7.3GB | MÃ©dia | Muito Boa | ProduÃ§Ã£o |');
console.log('');

console.log('ğŸ’¡ **DICAS IMPORTANTES**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

console.log('â€¢ **Primeira execuÃ§Ã£o:** Pode demorar para baixar o modelo');
console.log('â€¢ **Requisitos:** Pelo menos 8GB de RAM livre');
console.log('â€¢ **GPU:** Opcional, mas acelera muito (NVIDIA)');
console.log('â€¢ **Internet:** SÃ³ para baixar modelos (depois funciona offline)');
console.log('â€¢ **Privacidade:** 100% local, dados nÃ£o saem do seu PC');
console.log('');

console.log('ğŸ”„ **ALTERNAR ENTRE IAs**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

console.log('â€¢ **Mock AI:** yarn switch:ai mock');
console.log('â€¢ **Ollama:** yarn switch:ai ollama');
console.log('â€¢ **OpenAI:** yarn switch:ai openai');
console.log('');

console.log('ğŸ“š **RECURSOS ÃšTEIS**');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
console.log('â€¢ DocumentaÃ§Ã£o: https://ollama.ai/docs');
console.log('â€¢ Modelos disponÃ­veis: https://ollama.ai/library');
console.log('â€¢ Comunidade: https://github.com/ollama/ollama');
console.log('â€¢ Troubleshooting: https://ollama.ai/docs/troubleshooting');
console.log('');

console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
console.log('ğŸ’¡ **DICA:** Ollama Ã© perfeito para desenvolvimento e testes!');
console.log('   Use OpenAI apenas para produÃ§Ã£o ou demonstraÃ§Ãµes.');
console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”'); 